# Testing og inspeksjon – en kort dataanalyse

## Testing og inspeksjon - noen termer

### Defektkategorier

1. __Tilordning (Assignment)__
	Verdier blir tilordnet feil, eller ikke i det hele tatt.

2. __Sjekk (Checking)__
	Defekter som skyldes manglende eller feil validering av parametre eller data i conditional statements.

3. __Algoritme__
	Effektivitets- eller korrekthetsproblemer som kan fikses ved å bytte ut en algoritme eller datastruktur uten å endre design. Kan inneholde flere "Assignment"- og "Checking"-korreksjoner.

4. __Timing/serialisering__
	Nødvendig serialisering for en delt ressurs mangler,  feil ressurs er serialisert, eller så er feil serialiseringsteknikk brukt.

5. __Grensesnitt__
	Kommunikasjonsproblemer mellom moduler, componenter etc.

6. __Funksjon__
	Krever designendring, da defekten påvirker enten brukergrensesnitt, grensesnitt for andre produkter eller grensesnitt mot maskinvaren.

7. __Build/Package/Merge__
	Problemer med build-prosessen, i biblioteker eller i versjonskontrollen.

8. __Dokumentasjon__
	Problemer med brukermanual, installasjonsmanual eller kodekommentarer. Må ikke forveksles med funksjons- eller grensesnittfeil som beskrives i dokumentasjonen.


### Triggere
En trigger er en hendelse som gjør at man oppdager feil, gjør det mulig å evaluere effektiviteten av inspeksjoner og test scenarier. Det brukes forskjellige typer triggere for inspeksjon og for testing. I tillegg skilles det mellom triggere som brukes til white-box- og black-box-testing. 

#### Inspeksjonstriggere
En inspeksjonstrigger er en trigger som hjelper inspektører til å finne defekter i kode eller design dokumenter. Følgende triggere brukes for å finne defekter: 

1. __Overenstemmelse med design__
	Inspektørene finner defekter ved å sammenligne designelementer eller deler av koden med kravspesifikasjonen.

2. __Forstå detaljer__
	Inspektørene finner feil ved å undersøke strukturen til og/eller hvordan en komponent opererer i detalj. Denne triggeren kan deles ytterligere opp:

	a. __Operasjonell semantikk__
		Operasjonell semantikk beskriver hvilke sekvenser som blir utført i koden, altså meningen med programmet. Inspektøren har her den operasjonelle semantikken i bakhodet når defekten blir oppdaget.

	b. __Bivirkninger__
		Når inspektøren undersøker dokumentert eller implementert kode, oppdages det flere defekter som en bivirkning.

	c. __Samtidighet__
		For å kontrollere en delt ressurs trenger man å serialisere prosesser, og inspektøren kan oppdage defekter ved å inspisere denne prosessen.

3. __Bakoverkompatibilitet__
	Inspektøren finner inkompatibilitet mellom funksjonalitet beskrevet i dokumentasjonen eller koden, og tidligere versjoner av samme produkt. 

4. __Kompatibilitet med andre tjenester__
	Inspektøren oppdager inkompatibilitet mellom funksjonalitet beskrevet i dokumentasjonen eller koden og andre systemer eller tjenester produktet må snakke med.

5. __Udokumentert oppførsel__
	Inspektøren bruker sin erfaring og kunnskap til å forutse udokumentert oppførsel av systemet, og finner defekter på denne måten.

6. __Konsistens/Fullstendighet__
	Defekten kommer til syne pga inkonsistent eller ufullstendig dokumentasjon eller kode. 

7. __Språkavhengighet__
	Utvikleren finner en defekt under nærmere undersøkelse av språkspesifikke detaljer av implementasjonen av en komponent eller en funksjon.

#### Testtriggere
En trigger omfatter hensikten bak det å lage en test case, og test case finner defekter når den kjøres. Valget av triggere avhenger av om det er white-box- eller black-box-testing.

##### White-box-triggere

1. __Enkel stidekning (Simple Path Coverage)__
	Test case skrives for å undersøke visse branches i koden, på bakgrunn av kunnskap om disse. Hver branch testes én gang.

2. __Kombinatorisk stidekning (Combinational Path Coverage)__
	Nesten det samme som enkel stidekning, forskjellen er at hver branch testes mer enn én gang. Hver branch testes med flere forskjellige forhold.

3. __Bivirkninger__
	Defekten viser seg ved uforutsett oppførsel, som ikke ble spesifikt testet.

##### Black-box-triggere

1. __Dekningstest__
	En test case av en enkel kodedel ved bruk av en enkel input finner defekten. 

2. __Sekvensieringstest__
	Test casen som fant defekten kjørte sekvensielt, hvor to eller flere kodedeler (kan) kjøres uavhengig av hverandre.

3. __Interaksjonstest__
	Test casen som fant defekten startet en interaksjon mellom to eller flere kodedeler, hvor hver kodedel kan kjøres uavhengig av de andre. Interaksjonen mellom delene er mer komplisert enn å kjøre dem sekvensielt.

4. __Variasjonstest__
	Defekten blir oppdaget ved at man tester samme kode, men med forskjellige variasjoner av input. 

5. __Bivirkninger__
	Defekten viser seg ved uforutsett oppførsel, som ikke ble spesifikt testet.

## Testing og inspeksjon i praksis
Dette kapittelet presenterer funn ved testing og inspeksjon i praksis, basert på visse inspeksjons- og testdata.

### Inspeksjonsdata
Vi ser på inspeksjonsdata fra tre forskjellige utviklingsaktiviteter:

* Høynivå design: arkitekturelt design
* Lavnivå design: design av subsystemer, komponenter, modler og datamodeller
* Implementasjon: realisering, skrive kode

Disse utgjør venstresiden av V-modellen.

### Testdata
Vi ser også på testdata fra tre forskjellige utviklingsaktivteter:
	
* Unit testing: Tester små enheter som metoder eller klasser
* Verifikasjonstesting av funksjoner: Funksjonell testing av en komponent, et system eller et subsystem
* Verifikasjonstesting av system: tester systemet under ett, inkludert maskinvare og brukere

Disse utgjør høyresiden av V-modellen.

### Funn
Det viser seg at Paretos regel (om at 80% av effekten kommer fra 20% av årsakene) gjelder i det fleste tilfeller for både defektkategoriene og triggerne. Det vil si at omtrent 20% av defekttriggerne utløser 80% av defektene.

De vanligste defektene er relatert til enten dokumentasjon eller funksjon. Grensesnittdefekter er den eneste defektkategorien som kom på topp tre av de vanligste defektene både etter testing og etter inspeksjon. Samtidig er "bivirkninger" den eneste defekttriggeren som finnes blandt både testing- og inspeksjonsresultatene.

## Inspeksjon som en sosial prosess
Man må ta høyde for at inspeksjoner også inneholder en menneskelig faktor, og ikke bare tekniske detaljer. Det er viktig å tenke på hvordan personer:

* Samhandler
* Samarbeider

### Datakilder
Det har blitt gjennomført to eksperimenter relatert til de sosiale prosessene i inspeksjoner:

* UNSW - tre eksperimenter med 200 studenter, hvor fokuset var gevinst vs tap ved prosessen
* NTNU - to eksperimenter:
	* NTNU 1, 20 studenter fordelt på grupper hvor de bruker sjekklister
	* NTNU 2, 40 studenter 

#### Data fra UNSW-eksperimentet
Programmene som ble inspisert bestod av:

* 150 linjer lang kode med 19 defekter
* 350 linjer lang kode med 38 defekter



1. Hver student inspiserte koden individuelt og leverte inn hver sin rapport
2. Studentene ble tilfeldig plassert på grupper med tre personer, til sammen 40 grupper
3. Hver gruppe inspiserte koden sammen og leverte en rapport


For å forstå UNSW-eksperimentet, må man forstå to termer:

* Nominell gruppe - en gruppe personer som senere vil delta i en ekte gruppe, men som foreløpig jobber alene
* Ekte gruppe - en gruppe personer som kommuniserer direkte med hverandre, og samarbeider

Fra dette eksperimentet fant man at gruppen som enhet ikke fant 7 av defektene som enkeltpersonene fant. Samtidig fant de 5 defekter som enkeltpersonene ikke fant. Det vil si at prosessgevinst er 5 defekter, mens prosesstap er 7 defekter. Dette viser bare at det er store sjanser for at man ikke finner visse defekter ved å samarbeide i grupper, men samtidig er det store muligheter for å finne flere andre defekter.

Etter å ha analysert alle dataene fra dette eksperimentet, fant man at sannsynligheten for prosesstap (dvs. de defektene man taper/mister ved å bruke grupper) er 53%. Sannsynligheten for prosessgevinst (dvs. de ekstra defektene man finner ved å bruke grupper) var 30%. Man kan derfor konkludere med at det å bruke grupper ikke har så stor nytteverdi, og at man like gjerne kan droppe denne delen.

Det var en 10% sannsynlighet for at studentene rapporterte om defekter i rapporten, til tross for at ingen fant disse defektene. De defektene de fant var det 80-95% sannsynlighet for at de nevnte i rapportene.

Grunnen til at defekter som blir funnet på egenhånd blir forkastet i grupperapporten, kan være at majoriteten i gruppa bestemmer. Hvis et gruppemedlem finner en feil som ingen andre finner, kan det hende det gruppemedlemmet gir etter for gruppepress.

* Ved prosesstap finner man mange nye defekter, men fjerner også mange. 
* Ved prosessgevinst finner man mange nye defekter, men fjerner bare none få.
* Ved prosess-stabilitet finner mange defekter og fjerner omtrent like mange


Man kan dele gruppene opp i to deler:

* __Prosessgevinst__
	Alles bidrag teller, og man finner mange nye defekter
* __Prosesstap__
	Gruppepress, finner få nye defekter

#### Data fra NTNU1-eksperimentet
Det var som sagt 20 studenter med i eksperimentet, som inspiserte et program på 130 kodelinjer. Programmet inneholdt 13 defekter.

1. Gruppene bestod av to, tre eller fem studenter
2. Halve gruppe brukte en skreddersydd sjekkliste
3. Hver gruppe inspiserte koden og leverte en rapport

Gruppestørrelsen og bruken av sjekklister var hovedfokuset under eksperimentet. Dessuten ble effekten av kombinasjonen av de to også undersøkt.

Resultatene viser at de største gruppene fant fire flere defekter enn de minste gruppene. Bruk av sjekkliste ga ikke utslag på hvor mange defekter gruppa fant. De minste gruppene som brukte sjekklister fant to flere defekter enn de største gruppene som brukte defekter. Standardavviket gjør at man kan utelukke alt annet enn gruppestørrelsen.

#### Data fra NTNU2-eksperimentet
40 studenter som inspiserte et program på 130 kodelinjer. Programmet inneholdt 12 defekter.

1. 20 PhD-studenter og 20 ingeniørstudenter på tredjeåret
2. Hver student inspiserte koden individuelt og leverte inn rapport


Defektene gikk under følgende kategorier:

* __Feil kode__ - f.eks. feil parameter
* __Ekstra kode__ - f.eks. ubrukte variabler
* __Manglende kode__ - f.eks. ingen exception handling

De med minst erfaring og som nylig har kodet er bedre til å finne manglende kode, mens de med litt mer ingeniørutdanning var flinkere til å finne overflødig kode. Erfaring hadde ingen innvirkning på hvor flinke studentene var på å finne feil kode. 